--- a/app.py
+++ b/sandbox/app.py
@@ -1,6 +1,7 @@
 from flask import Flask, render_template, send_from_directory, request, jsonify
 from flask_socketio import SocketIO
 from flask_cors import CORS
-import google.generativeai as genai
+import vertexai
+from vertexai.generative_models import GenerativeModel
 import os
 import logging
 import json
@@ -13,15 +14,6 @@
 import inspect_db as db_inspector
 import debugpy
 import time
-
-# --- Function to load API key from a file ---
-def load_api_key():
-    try:
-        key_path = os.path.join(os.path.dirname(__file__), 'private_data', 'Gemini_API_Key.txt')
-        with open(key_path, 'r') as f:
-            return f.read().strip()
-    except FileNotFoundError:
-        return None
 
 # --- Function to load the system prompt from a file ---
 def load_system_prompt():
@@ -32,20 +24,29 @@
     except FileNotFoundError:
         return "You are a helpful assistant but were unable to locate or open system_prompt.txt, and thus do not have access to your core directives."
 
-# --- Function to load the model definition from a file ---
-def load_model_definition():
+# --- NEW: Functions to load Vertex AI configuration ---
+def load_vertex_config():
     try:
-        model_definition_path = os.path.join(os.path.dirname(__file__), 'public_data', 'model_definition.txt')
-        with open(model_definition_path, 'r') as f:
-            return f.read()
-    except FileNotFoundError:
-        return 'gemini-2.5-pro'
+        config_path = os.path.join(os.path.dirname(__file__), 'private_data', 'vertex_ai_config.json')
+        with open(config_path, 'r') as f:
+            config = json.load(f)
+            return config.get("project_id"), config.get("location"), config.get("model_name", "gemini-1.5-pro-001")
+    except (FileNotFoundError, json.JSONDecodeError) as e:
+        logging.error(f"Could not load Vertex AI config: {e}")
+        return None, None, "gemini-1.5-pro-001"
 
 # --- CONFIGURATION ---
-API_KEY = load_api_key()
 SYSTEM_PROMPT = load_system_prompt()
-MODEL_DEFINITION = load_model_definition()
+PROJECT_ID, LOCATION, MODEL_NAME = load_vertex_config()
 API_STATS_FILE = os.path.join(os.path.dirname(__file__), 'api_usage.json')
 app = Flask(__name__)
 CORS(app)
@@ -56,26 +57,23 @@
 # --- Setup Logging ---
 logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', handlers=[logging.FileHandler("agent.log"), logging.StreamHandler()])
 
-# --- GEMINI SETUP ---
+# --- VERTEX AI SETUP ---
 model = None
-if API_KEY:
+if PROJECT_ID and LOCATION:
     try:
-        genai.configure(api_key=API_KEY)
+        vertexai.init(project=PROJECT_ID, location=LOCATION)
         safety_settings = {
             'HARM_CATEGORY_HARASSMENT': 'BLOCK_NONE',
             'HARM_CATEGORY_HATE_SPEECH': 'BLOCK_NONE',
             'HARM_CATEGORY_SEXUALLY_EXPLICIT': 'BLOCK_NONE',
             'HARM_CATEGORY_DANGEROUS_CONTENT': 'BLOCK_NONE',
         }
-        model = genai.GenerativeModel(\n            model_name=MODEL_DEFINITION,\n            system_instruction=SYSTEM_PROMPT,\n            safety_settings=safety_settings\n        )\n        logging.info(\"Gemini API configured successfully.\")\n    except Exception as e:\n        logging.critical(f\"FATAL: Failed to configure Gemini API. Error: {e}\")\n else:\n    logging.critical(\"FATAL: Gemini API key not loaded.\")\n+        model = GenerativeModel(
+            MODEL_NAME,
+            system_instruction=[SYSTEM_PROMPT]
+        )
+        logging.info("Vertex AI Gemini Pro model initialized successfully.")
+    except Exception as e:
+        logging.critical(f"FATAL: Failed to initialize Vertex AI model. Error: {e}")
+else:
+    logging.critical("FATAL: Vertex AI project ID or location not found in config.")
 
 # --- API Usage Tracking ---
 def load_api_stats():