"""
Provides robust parsing capabilities for converting raw LLM outputs into
structured data.

This module acts as a resilient "translation layer" between the unpredictable,
often messy, raw text generated by a large language model and the clean,
structured ParsedAgentResponse object that the rest of the application requires.
It is designed to handle common failure modes like mixed prose and JSON,
malformed JSON, and missing code fences.
"""

import re
import json
from data_models import ToolCommand, ParsedAgentResponse


def is_prose_effectively_empty(prose_string: str | None) -> bool:
    """
    Checks if a string contains meaningful content beyond a potential timestamp.

    Args:
        prose_string: The string to check.

    Returns:
        True if the string is None, empty, or contains only a timestamp and whitespace.
    """
    if not prose_string:
        return True
    # This regex matches the standard timestamp format (e.g., [06AUG2025_040527PM])
    # at the very beginning of the string.
    timestamp_pattern = r"^\[\d{2}[A-Z]{3}\d{4}_\d{2}\d{2}\d{2}[AP]M\]"
    # We remove the timestamp and then check if anything is left.
    prose_without_timestamp = re.sub(timestamp_pattern, "", prose_string.strip())
    # The prose is considered empty if nothing remains after stripping whitespace.
    return prose_without_timestamp.strip() == ""


def parse_agent_response(response_text: str) -> ParsedAgentResponse:
    """
    Parses a potentially messy agent response to separate prose from a valid command JSON.

    This function is a critical component that acts as a robust translation layer
    between the often unpredictable raw text output of a large language model and
    the clean, structured data the application needs to operate. It is designed
    to handle "mixed messages" containing both natural language text (prose) and
    a command in a JSON block.

    It addresses several common failure modes, including:
    - LLMs forgetting to use markdown fences (```json).
    - Malformed JSON strings with unescaped characters.
    - The presence of code or data payloads that should not be part of the command JSON.

    The process involves masking payloads, attempting to extract JSON using two
    different methods (fences and brace-counting), repairing the extracted JSON if
    necessary, and finally constructing a structured ParsedAgentResponse object.

    Args:
        response_text: The raw string response from the agent.

    Returns:
        A ParsedAgentResponse object containing:
        - `prose`: The cleaned natural language string (or None).
        - `command`: The parsed command as a ToolCommand object (or None).
        - `is_prose_empty`: A boolean flag indicating if the prose is empty
                          or contains only a timestamp.
    """
    # Step 1: Create a sanitized version of the text with all payload blocks removed.
    # This prevents the JSON extraction logic from accidentally finding JSON within a payload.
    sanitized_text = _mask_payloads(response_text)
    
    # Step 2: Attempt to find a command JSON within the sanitized text.
    # First, try finding a command enclosed in standard ```json fences.
    full_match_block, command_json_str = _extract_json_with_fences(sanitized_text)

    # If no fences are found, fall back to a more complex brace-counting method.
    if not command_json_str:
        full_match_block, command_json_str = _extract_json_with_brace_counting(sanitized_text)

    # Step 3: If a potential command was found, parse it and construct the final prose.
    if command_json_str:
        try:
            # First, try to load the JSON as is.
            command_json = json.loads(command_json_str)
        except json.JSONDecodeError:
            # If that fails, attempt to repair common JSON errors.
            repaired_json_str = _repair_json(command_json_str)
            try:
                command_json = json.loads(repaired_json_str)
            except json.JSONDecodeError:
                # If repair also fails, give up and treat the entire response as prose.
                return ParsedAgentResponse(
                    prose=_clean_prose(response_text),
                    is_prose_empty=is_prose_effectively_empty(response_text)
                )

        # Step 4: Validate the parsed JSON against our ToolCommand model.
        validated_command = ToolCommand.model_validate(command_json)
        # Construct the final prose by removing the command block from the original text.
        final_prose = response_text.replace(full_match_block, "", 1).strip()
        
        return ParsedAgentResponse(
            prose=_clean_prose(final_prose),
            command=validated_command,
            is_prose_empty=is_prose_effectively_empty(final_prose)
        )

    # If no JSON command was ever found, the entire response is prose.
    return ParsedAgentResponse(
        prose=_clean_prose(response_text),
        is_prose_empty=is_prose_effectively_empty(response_text)
    )


def _mask_payloads(text: str) -> str:
    """
    Finds and removes all payload blocks (e.g., START @@... END @@...).
    """
    # The \1 is a backreference to the captured group (@@\w+), ensuring that
    # a "START @@PLACEHOLDER" is only matched with its corresponding "END @@PLACEHOLDER".
    pattern = re.compile(r"START (@@\w+).*?END \1", re.DOTALL)
    return pattern.sub("", text)


def _extract_json_with_fences(text: str) -> tuple[str | None, str | None]:
    """
    Extracts the largest JSON block enclosed in ```json fences.
    """
    pattern = r"(```json\s*\n?({.*?})\s*\n?```)"
    matches = list(re.finditer(pattern, text, re.DOTALL))
    if not matches:
        return None, None
    # If multiple JSON blocks exist, assume the largest one is the intended command.
    largest_match = max(matches, key=lambda m: len(m.group(2)))
    # Return both the full block (with fences) and the inner JSON content.
    return largest_match.group(1), largest_match.group(2)


def _extract_json_with_brace_counting(text: str) -> tuple[str | None, str | None]:
    """
    Finds the largest valid JSON object in a string by counting braces.
    This is a fallback for when the LLM forgets to use markdown fences.
    """
    best_json_candidate = None
    start_indices = [m.start() for m in re.finditer("{", text)]
    for start_index in start_indices:
        open_braces = 0
        in_string = False
        for i, char in enumerate(text[start_index:]):
            # Toggle in_string flag if we encounter a quote that isn't escaped.
            if char == '"' and (i == 0 or text[start_index + i - 1] != "\\"):
                in_string = not in_string
            # Only count braces if we're not inside a string value.
            if not in_string:
                if char == "{":
                    open_braces += 1
                elif char == "}":
                    open_braces -= 1
            # When braces are balanced, we may have found a complete JSON object.
            if open_braces == 0:
                potential_json = text[start_index : start_index + i + 1]
                try:
                    repaired_potential = _repair_json(potential_json)
                    json.loads(repaired_potential)
                    # If it's valid and the largest found so far, store it.
                    if not best_json_candidate or len(repaired_potential) > len(best_json_candidate):
                        best_json_candidate = repaired_potential
                except json.JSONDecodeError:
                    continue # Not a valid JSON, keep searching.
    # Returns the candidate for both tuple values for a consistent interface.
    return best_json_candidate, best_json_candidate


def _repair_json(s: str) -> str:
    """
    Attempts to repair a malformed JSON string by iteratively fixing common errors.
    """
    s_before_loop = s
    for _ in range(1000): # Max iterations to prevent infinite loops.
        try:
            json.loads(s)
            return s # If parsing succeeds, the JSON is valid.
        except json.JSONDecodeError as e:
            error_fixed = False
            # Fix 1: Unescaped control characters (e.g., newlines in string content).
            if "Invalid control character" in e.msg:
                char_to_escape = s[e.pos]
                escape_map = {"\n": "\\n", "\r": "\\r", "\t": "\\t"}
                if char_to_escape in escape_map:
                    s = s[:e.pos] + escape_map[char_to_escape] + s[e.pos + 1:]
                    error_fixed = True
            # Fix 2: Unescaped double quotes inside a string.
            elif "Expecting" in e.msg or "Unterminated string" in e.msg:
                quote_pos = s.rfind('"', 0, e.pos)
                if quote_pos != -1:
                    # Check if it's already properly escaped by counting preceding backslashes.
                    p, slashes = quote_pos - 1, 0
                    while p >= 0 and s[p] == "\\":
                        slashes += 1
                        p -= 1
                    # If the number of slashes is even, the quote is unescaped. Add a slash.
                    if slashes % 2 == 0:
                        s = s[:quote_pos] + "\\" + s[quote_pos:]
                        error_fixed = True
            # If we couldn't identify a fix, break to avoid mangling the string.
            if not error_fixed:
                return s_before_loop
    return s


def _clean_prose(prose: str | None) -> str | None:
    """A simple utility to clean up the final prose string."""
    return prose.strip() if prose else None


def _handle_payloads(prose: str | None, command: ToolCommand | None) -> tuple[str | None, ToolCommand | None]:
    """
    Finds and replaces payload placeholders in a command's parameters
    with content defined in START/END blocks within the prose.
    """
    if not command or not command.parameters or not prose:
        return prose, command
    params = command.parameters
    placeholders_to_process = [(k, v) for k, v in params.items() if isinstance(v, str) and v.startswith("@@")]
    placeholders_found = []
    for key, placeholder in placeholders_to_process:
        start_marker, end_marker = f"START {placeholder}", f"END {placeholder}"
        start_index = prose.find(start_marker)
        end_index = prose.find(end_marker, start_index) if start_index != -1 else -1
        if start_index != -1 and end_index != -1:
            # Extract content between markers and update the command's parameters.
            content_start = start_index + len(start_marker)
            params[key] = prose[content_start:end_index].strip()
            placeholders_found.append(placeholder)
    # If we processed any placeholders, remove the definition blocks from the prose.
    if placeholders_found:
        temp_prose = prose
        for placeholder in placeholders_found:
            pattern = re.compile(f"START {re.escape(placeholder)}.*?END {re.escape(placeholder)}", re.DOTALL)
            temp_prose = pattern.sub("", temp_prose)
        prose = temp_prose.strip()
    return prose, command
